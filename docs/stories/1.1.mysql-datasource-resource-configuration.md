# <!-- Powered by BMADâ„¢ Core -->

# Story 1.1: MySQL Datasource & Resource Configuration

## Status
Approved

## Story
**As a** data engineer using the data-factory platform,
**I want** to configure MySQL datasources and resources with connection validation and batch/stream collection task setup through the data-terminal UI,
**so that** I can establish reliable data connections and select appropriate data collection modes for my ETL pipelines.

## Acceptance Criteria
1. Users can configure MySQL datasource connection parameters
2. Connection validation provides immediate feedback  
3. Users can configure MySQL/Doris target resources
4. Batch and stream collection modes are selectable
5. Configuration persists in data-engine database

## Tasks / Subtasks
- [ ] Task 1: Extend DataSource model for MySQL connection parameters (AC: 1, 5)
  - [ ] Add MySQL-specific connection fields to DataSource model
  - [ ] Update database schema for MySQL configuration storage
  - [ ] Implement validation rules for MySQL connection parameters
- [ ] Task 2: Implement MySQL connection validation service (AC: 2)
  - [ ] Create MySQL connection validation service in backend
  - [ ] Add real-time connection testing endpoint
  - [ ] Implement connection status feedback mechanism
- [ ] Task 3: Create MySQL/Doris resource configuration (AC: 3, 5)
  - [ ] Extend Resource model for MySQL/Doris resource types
  - [ ] Add resource configuration validation logic
  - [ ] Update database persistence layer for new resource types
- [ ] Task 4: Add batch/stream collection mode selection (AC: 4)
  - [ ] Add collection mode enumeration to DataSource model
  - [ ] Create UI components for mode selection
  - [ ] Implement mode-specific configuration options
- [ ] Task 5: Update data-terminal UI for MySQL configuration (AC: 1, 2, 3, 4)
  - [ ] Create MySQL datasource configuration form component
  - [ ] Add connection validation UI with real-time feedback
  - [ ] Create MySQL/Doris resource configuration form
  - [ ] Add batch/stream mode selection UI elements
- [ ] Task 6: Unit and integration testing
  - [ ] Write unit tests for new model validations
  - [ ] Test MySQL connection validation service
  - [ ] Test UI form components and validation feedback
  - [ ] Integration tests for database persistence

## Dev Notes

### Architecture Context
**Source**: `docs/data-terminal-brownfield-architecture.md`

**Current System Reality**:
- data-terminal is a Rust-based full-stack application with Axum backend and Dioxus frontend
- Current DataSource model supports basic connection configuration via `serde_json::Value`
- Resource model supports multiple categories and types but needs MySQL/Doris extension
- Database uses MySQL with `df_` table prefix

**Key Technical Details**:

**Backend (Rust + Axum) - File Locations**:
- **DataSource Model**: `data-terminal/backend/src/models/datasource.rs:56` - Current model supports category, type, and connection_config JSON
- **Resource Model**: `data-terminal/backend/src/models/resource.rs:75` - Supports category, resource_type, and config JSON  
- **DataSource Service**: `data-terminal/backend/src/services/datasource.rs` - Business logic layer for datasource management
- **Resource Service**: `data-terminal/backend/src/services/resource.rs` - Business logic layer for resource management
- **API Routes**: `data-terminal/backend/src/routes/` - REST endpoints for CRUD operations
- **Database Config**: `data-terminal/backend/config/Setting.toml` - MySQL connection configuration

**Frontend (Dioxus + WebAssembly) - File Locations**:
- **DataSource Page**: `data-terminal/frontend/src/pages/datasource.rs` - Current datasource management UI
- **Resource Page**: `data-terminal/frontend/src/pages/resource.rs` - Current resource management UI  
- **Components**: `data-terminal/frontend/src/components/` - Reusable UI components
- **Models**: `data-terminal/frontend/src/models/` - Frontend DTOs matching backend models
- **HTTP Client**: `data-terminal/frontend/src/utils/` - REST API communication

**Current API Endpoints** [Source: docs/data-terminal-brownfield-architecture.md#api-specifications]:
```
POST   /datasources   - Add data source connection
PUT    /datasources   - Update data source  
DELETE /datasources/{id} - Remove data source
GET    /datasources/{id} - Get data source details
GET    /datasources   - List data sources with pagination

POST   /resources     - Add infrastructure resource
PUT    /resources     - Update resource configuration
DELETE /resources/{id} - Remove resource
GET    /resources/{id} - Get resource details  
GET    /resources     - List available resources
```

**Data Models Extensions Needed**:

**DataSource Model Enhancements** [Source: docs/data-terminal-brownfield-architecture.md#core-data-models]:
- Current: `datasource_type: DataSourceType` (Mysql|Postgres|QueryApi|SubscribeApi)
- Extension needed: MySQL-specific connection parameters in connection_config JSON
- New field: Collection mode enumeration (Batch|Stream)

**Resource Model Enhancements**:
- Current: `resource_type: ResourceType` (Mysql|Postgres|Doris|Hdfs|Kafka|Spark|Flink)
- Extension needed: MySQL/Doris specific configuration in config JSON field

**Integration with data-engine**:
[Source: docs/data-terminal-brownfield-architecture.md#integration-point-with-data-engine]
- data-terminal serves as management interface
- data-engine (Java-based) contains actual ETL processing capabilities  
- Integration pattern: data-terminal manages configuration, data-engine executes processing
- Future: HTTP/gRPC communication with data-engine for ETL execution

**Technology Stack** [Source: docs/data-terminal-brownfield-architecture.md#actual-tech-stack]:
- Backend: Rust with Axum 0.8.4, SQLx 0.8.6 for MySQL, Shaku 0.6.2 for DI
- Frontend: Dioxus 0.6.3 (React-like), DaisyUI + Tailwind CSS
- Database: MySQL with async SQLx and compile-time query validation
- Authentication: JWT (jsonwebtoken 9.3.1)

### Project Structure Notes
Project follows Cargo workspace structure with clean architecture patterns:
- Backend services use dependency injection via Shaku
- Frontend uses component-based architecture with Dioxus
- Database layer uses SQLx with compile-time validation
- All models use serde for JSON serialization

### Testing
**Testing Standards** [Source: docs/data-terminal-brownfield-architecture.md#testing-reality]:
- **Current Test Coverage**: Basic model validation tests
- **Test Location**: Unit tests in respective module files (`backend/src/models/`, `backend/src/services/`)
- **Test Framework**: Rust's built-in test framework with `cargo test`
- **Testing Requirements**: 
  - Unit tests for model validation and business logic
  - Integration tests for database operations
  - Frontend component tests with Dioxus testing utilities
- **Commands**: 
  - Backend: `cd backend && cargo test`
  - Frontend: `cd frontend && cargo test`

No specific testing strategy document found in architecture docs - using standard Rust testing practices.

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-19 | 1.0 | Initial story creation | Bob (Scrum Master) |
| 2025-09-19 | 1.1 | Story approved after validation | Bob (Scrum Master) |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used
Claude Sonnet 4 (claude-sonnet-4-20250514) - Full Stack Developer Agent

### Debug Log References  
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

## QA Results
*Results from QA Agent review will be populated here*